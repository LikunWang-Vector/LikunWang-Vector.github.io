<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>07. Practical: Scraping Movie Torrent Links with Python Regex | Likun Wang | ç‹ç«‹å¤</title><meta name="author" content="Likun Wang (ç‹ç«‹å¤)"><meta name="copyright" content="Likun Wang (ç‹ç«‹å¤)"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="This article was migrated from CSDN blogOriginal link: 07. Practical: Scraping Movie Torrent Links with Python RegexğŸ“Š 1251 views | ğŸ‘ 3 likes | ğŸ’¬ 2 comments | â­ 8 favorites  Table of Contents Intro">
<meta property="og:type" content="article">
<meta property="og:title" content="07. Practical: Scraping Movie Torrent Links with Python Regex">
<meta property="og:url" content="https://your-domain.com/2022/12/29/en/07-Practical-Scraping-Movie-Torrent-Links-with-Python-Regex/index.html">
<meta property="og:site_name" content="Likun Wang | ç‹ç«‹å¤">
<meta property="og:description" content="This article was migrated from CSDN blogOriginal link: 07. Practical: Scraping Movie Torrent Links with Python RegexğŸ“Š 1251 views | ğŸ‘ 3 likes | ğŸ’¬ 2 comments | â­ 8 favorites  Table of Contents Intro">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://your-domain.com/images/posts/07.-%E5%AE%9E%E6%88%98%EF%BC%9APython%E6%AD%A3%E5%88%99%E6%B3%95%E6%8A%93%E5%8F%96%E6%9F%90%E7%BD%91%E7%AB%992022%E5%BF%85%E7%9C%8B%E7%89%87%E8%BF%85%E9%9B%B7/f09781cf5d77.png">
<meta property="article:published_time" content="2022-12-29T15:00:00.000Z">
<meta property="article:modified_time" content="2022-12-29T15:00:00.000Z">
<meta property="article:author" content="Likun Wang (ç‹ç«‹å¤)">
<meta property="article:tag" content="programming">
<meta property="article:tag" content="pycharm">
<meta property="article:tag" content="python">
<meta property="article:tag" content="regular expressions">
<meta property="article:tag" content="web scraping">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://your-domain.com/images/posts/07.-%E5%AE%9E%E6%88%98%EF%BC%9APython%E6%AD%A3%E5%88%99%E6%B3%95%E6%8A%93%E5%8F%96%E6%9F%90%E7%BD%91%E7%AB%992022%E5%BF%85%E7%9C%8B%E7%89%87%E8%BF%85%E9%9B%B7/f09781cf5d77.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "07. Practical: Scraping Movie Torrent Links with Python Regex",
  "url": "https://your-domain.com/2022/12/29/en/07-Practical-Scraping-Movie-Torrent-Links-with-Python-Regex/",
  "image": "https://your-domain.com/images/posts/07.-%E5%AE%9E%E6%88%98%EF%BC%9APython%E6%AD%A3%E5%88%99%E6%B3%95%E6%8A%93%E5%8F%96%E6%9F%90%E7%BD%91%E7%AB%992022%E5%BF%85%E7%9C%8B%E7%89%87%E8%BF%85%E9%9B%B7/f09781cf5d77.png",
  "datePublished": "2022-12-29T15:00:00.000Z",
  "dateModified": "2022-12-29T15:00:00.000Z",
  "author": [
    {
      "@type": "Person",
      "name": "Likun Wang (ç‹ç«‹å¤)",
      "url": "https://github.com/veckun"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://your-domain.com/2022/12/29/en/07-Practical-Scraping-Movie-Torrent-Links-with-Python-Regex/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.3"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@6.1.7/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          const mediaQueryDark = window.matchMedia('(prefers-color-scheme: dark)')
          const mediaQueryLight = window.matchMedia('(prefers-color-scheme: light)')

          if (theme === undefined) {
            if (mediaQueryLight.matches) activateLightMode()
            else if (mediaQueryDark.matches) activateDarkMode()
            else {
              const hour = new Date().getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            mediaQueryDark.addEventListener('change', () => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else {
            theme === 'light' ? activateLightMode() : activateDarkMode()
          }
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"pagination":{"enable":false,"hitsPerPage":8},"languages":{"hits_empty":"No results found for: ${query}","hits_stats":"${hits} articles found"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400,"highlightFullpage":true,"highlightMacStyle":true},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":50,"languages":{"author":"Author: Likun Wang (ç‹ç«‹å¤)","link":"Link: ","source":"Source: Likun Wang | ç‹ç«‹å¤","info":"Copyright belongs to the author. For commercial use, please contact the author for authorization. For non-commercial use, please indicate the source."}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"You have switched to Traditional Chinese","cht_to_chs":"You have switched to Simplified Chinese","day_to_night":"You have switched to Dark Mode","night_to_day":"You have switched to Light Mode","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: true,
  isAnchor: true,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '07. Practical: Scraping Movie Torrent Links with Python Regex',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/csdn-stats.css"><link rel="stylesheet" href="/css/lang-switch.css"><meta name="generator" content="Hexo 8.1.1"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      if ($loadingBox.classList.contains('loaded')) return
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()

  if (document.readyState === 'complete') {
    preloader.endLoading()
  } else {
    window.addEventListener('load', preloader.endLoading)
    document.addEventListener('DOMContentLoaded', preloader.endLoading)
    // Add timeout protection: force end after 7 seconds
    setTimeout(preloader.endLoading, 7000)
  }

  if (true) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">302</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">311</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">21</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/cv/"><i class="fa-fw fas fa-graduation-cap"></i><span> CV</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url(/images/posts/07.-%E5%AE%9E%E6%88%98%EF%BC%9APython%E6%AD%A3%E5%88%99%E6%B3%95%E6%8A%93%E5%8F%96%E6%9F%90%E7%BD%91%E7%AB%992022%E5%BF%85%E7%9C%8B%E7%89%87%E8%BF%85%E9%9B%B7/f09781cf5d77.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Likun Wang | ç‹ç«‹å¤</span></a><a class="nav-page-title" href="/"><span class="site-name">07. Practical: Scraping Movie Torrent Links with Python Regex</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/cv/"><i class="fa-fw fas fa-graduation-cap"></i><span> CV</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">07. Practical: Scraping Movie Torrent Links with Python Regex</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-12-29T15:00:00.000Z" title="Created 2022-12-30 00:00:00">2022-12-30</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-12-29T15:00:00.000Z" title="Updated 2022-12-30 00:00:00">2022-12-30</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Python-Web-Scraping-Tutorial/">Python Web Scraping Tutorial</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">1.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>7mins</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:180,&quot;messagePrev&quot;:&quot;This article was last updated&quot;,&quot;messageNext&quot;:&quot;days ago. The content may be outdated.&quot;,&quot;postUpdate&quot;:&quot;2022-12-30 00:00:00&quot;}" hidden></div><blockquote>
<p>This article was migrated from CSDN blog<br>Original link: <a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_59180666/article/details/128492270">07. Practical: Scraping Movie Torrent Links with Python Regex</a><br>ğŸ“Š 1251 views | ğŸ‘ 3 likes | ğŸ’¬ 2 comments | â­ 8 favorites</p>
</blockquote>
<p><strong>Table of Contents</strong></p>
<p>Introduction</p>
<p>Objective</p>
<p>Approach</p>
<p>Code Implementation</p>
<p>Step 1: Import Libraries</p>
<p>Step 2: Request Source Code</p>
<p>Step 3: Debug Step 2</p>
<p>Step 4: Locate Information with Regex</p>
<p>Step 5: Access and Extract Sub-page Content</p>
<p>Complete Code</p>
<p>Results</p>
<p>Summary</p>
<hr>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>In the previous chapter, we covered scraping movie Top 250 information with Python regex. This chapter presents another simple regex scraping example: extracting torrent resources from a movie website!</p>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/posts/07.-%E5%AE%9E%E6%88%98%EF%BC%9APython%E6%AD%A3%E5%88%99%E6%B3%95%E6%8A%93%E5%8F%96%E6%9F%90%E7%BD%91%E7%AB%992022%E5%BF%85%E7%9C%8B%E7%89%87%E8%BF%85%E9%9B%B7/f09781cf5d77.png"></p>
<hr>
<h3 id="Objective"><a href="#Objective" class="headerlink" title="Objective"></a>Objective</h3><p>Extract movie names and corresponding torrent links from a â€œ2022 Must-Watch Moviesâ€ list on a website.</p>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/posts/07.-%E5%AE%9E%E6%88%98%EF%BC%9APython%E6%AD%A3%E5%88%99%E6%B3%95%E6%8A%93%E5%8F%96%E6%9F%90%E7%BD%91%E7%AB%992022%E5%BF%85%E7%9C%8B%E7%89%87%E8%BF%85%E9%9B%B7/cceba41eb059.png"></p>
<hr>
<h3 id="Approach"><a href="#Approach" class="headerlink" title="Approach"></a>Approach</h3><ol>
<li>Locate the 2022 Must-Watch Movies section</li>
<li>Extract sub-page links from the list</li>
<li>Request sub-page links to get the download addresses we want</li>
</ol>
<hr>
<h3 id="Code-Implementation"><a href="#Code-Implementation" class="headerlink" title="Code Implementation"></a>Code Implementation</h3><h4 id="Step-1-Import-Libraries"><a href="#Step-1-Import-Libraries" class="headerlink" title="Step 1: Import Libraries"></a>Step 1: Import Libraries</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> requests</span><br></pre></td></tr></table></figure>

<p>Quick review: the <code>re</code> library is for Regular Expressions - Pythonâ€™s regex library for data parsing. The <code>requests</code> library is what we use to make web requests.</p>
<h4 id="Step-2-Request-Source-Code"><a href="#Step-2-Request-Source-Code" class="headerlink" title="Step 2: Request Source Code"></a>Step 2: Request Source Code</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">domain = <span class="string">&quot;target_url_here&quot;</span>  <span class="comment"># domain is just another way of saying URL</span></span><br><span class="line">resp = requests.get(domain)</span><br><span class="line"><span class="comment"># If error occurs, might be an https issue. Add parameter &#x27;verify=False&#x27; to skip security verification</span></span><br><span class="line"><span class="built_in">print</span>(resp.text)</span><br></pre></td></tr></table></figure>

<p>Two potential issues here:</p>
<ol>
<li><p>If <code>resp</code> throws an error, it might be an HTTPS issue. The difference between https and http is security verification. If we get an error accessing an https page, add <code>verify=False</code> to <code>requests.get()</code> to skip security verification.</p>
</li>
<li><p>When printing the source code, Chinese characters might appear garbled. This is definitely an encoding issue! HTMLâ€™s default encoding matches PyCharmâ€™s - both use UTF-8. But when garbled text appears, we need to find out how this webpageâ€™s encoding differs.</p>
</li>
</ol>
<h4 id="Step-3-Debug-Step-2"><a href="#Step-3-Debug-Step-2" class="headerlink" title="Step 3: Debug Step 2"></a>Step 3: Debug Step 2</h4><ol>
<li>Modify the resp line:</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">resp = requests.get(domain, verify=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>Observe the webpage source code header tag which specifies the encoding:</li>
</ol>
<p><code>&lt;META http-equiv=Content-Type content=&quot;text/html; charset=gb2312&quot;&gt;</code> shows <code>charset=gb2312</code>, so we should use gb2312 encoding.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">resp.encoding = <span class="string">&#x27;gb2312&#x27;</span>  <span class="comment"># Specify character set</span></span><br><span class="line"><span class="built_in">print</span>(resp.text)</span><br><span class="line">resp.close()</span><br></pre></td></tr></table></figure>

<p>Now printing the source code wonâ€™t show garbled text.</p>
<h4 id="Step-4-Locate-Information-with-Regex"><a href="#Step-4-Locate-Information-with-Regex" class="headerlink" title="Step 4: Locate Information with Regex"></a>Step 4: Locate Information with Regex</h4><ol>
<li>First check the page source code to locate elements:</li>
</ol>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/posts/07.-%E5%AE%9E%E6%88%98%EF%BC%9APython%E6%AD%A3%E5%88%99%E6%B3%95%E6%8A%93%E5%8F%96%E6%9F%90%E7%BD%91%E7%AB%992022%E5%BF%85%E7%9C%8B%E7%89%87%E8%BF%85%E9%9B%B7/1ad3ab60dc9c.png"></p>
<p>We can observe that starting from <code>&lt;ul&gt;</code>, each <code>&lt;li&gt;</code> contains the resource name and link we need.</p>
<p>Note: <code>&lt;ul&gt;</code> represents an unordered list, and each <code>&lt;li&gt;</code> represents a list item; <code>&lt;div&gt;</code> is a block-level element indicating this section is a whole unit.</p>
<ol start="2">
<li>Use regex to locate the above source code:</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Successfully located</span></span><br><span class="line">obj1 = re.<span class="built_in">compile</span>(<span class="string">r&quot;2022å¿…çœ‹çƒ­ç‰‡.*?&lt;ul&gt;(?P&lt;ul&gt;.*?)&lt;/ul&gt;&quot;</span>, re.S)</span><br><span class="line">result1 = obj1.finditer(resp.text)</span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> result1:</span><br><span class="line">    ul = it.group(<span class="string">&#x27;ul&#x27;</span>)</span><br><span class="line">    <span class="comment"># print(ul)</span></span><br></pre></td></tr></table></figure>

<p>We use lazy matching to extract the information wrapped in <code>&lt;li&gt;</code> tags. Itâ€™s quite accurate, but we canâ€™t use it directly - we need to refine it and extract the specific details.</p>
<ol start="3">
<li>Apply regex again to get the desired information:</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># In HTML, the &lt;a&gt; tag represents a hyperlink. Clicking it jumps to the href link.</span></span><br><span class="line"><span class="comment"># title is the tooltip text that appears on hover. We mainly need the sub-page link in href.</span></span><br><span class="line"><span class="comment"># Extract sub-page links</span></span><br><span class="line">obj2 = re.<span class="built_in">compile</span>(<span class="string">r&quot;&lt;a href=&#x27;(?P&lt;href&gt;.*?)&#x27;&quot;</span>, re.S)</span><br><span class="line">result2 = obj2.finditer(ul)</span><br><span class="line">child_href_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> result2:</span><br><span class="line">    href = i.group(<span class="string">&#x27;href&#x27;</span>)</span><br><span class="line">    <span class="comment"># Concatenate sub-page URL: domain + sub-page address (extra slash needs to be stripped)</span></span><br><span class="line">    child_href = domain + href.strip(<span class="string">&quot;/&quot;</span>)</span><br><span class="line">    <span class="comment"># print(child_href)</span></span><br><span class="line">    <span class="comment"># For convenience, store them in a list</span></span><br><span class="line">    child_href_list.append(child_href)  <span class="comment"># Save sub-page links</span></span><br></pre></td></tr></table></figure>

<p>The <code>&lt;a&gt;</code> tag represents a hyperlink, and the <code>href</code> attribute references the sub-link, which is a path added to the current domain to locate what we need. So we concatenate the domain from our earlier code with the sub-page address.</p>
<p>When printed, we find an extra slash in the link. We use the <code>strip</code> function to remove it, then recursively save to the list.</p>
<h4 id="Step-5-Access-and-Extract-Sub-page-Content"><a href="#Step-5-Access-and-Extract-Sub-page-Content" class="headerlink" title="Step 5: Access and Extract Sub-page Content"></a>Step 5: Access and Extract Sub-page Content</h4><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/posts/07.-%E5%AE%9E%E6%88%98%EF%BC%9APython%E6%AD%A3%E5%88%99%E6%B3%95%E6%8A%93%E5%8F%96%E6%9F%90%E7%BD%91%E7%AB%992022%E5%BF%85%E7%9C%8B%E7%89%87%E8%BF%85%E9%9B%B7/ecbe88cd36c5.png"></p>
<p>The information we need appears starting from line 90 in the source code, as shown.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Extract sub-page content</span></span><br><span class="line">obj3 = re.<span class="built_in">compile</span>(<span class="string">r&#x27;â—ç‰‡ å(?P&lt;moviename&gt;.*?)&lt;br /&gt;.*?&lt;td &#x27;</span></span><br><span class="line">                  <span class="string">r&#x27;style=&quot;WORD-WRAP: break-word&quot; bgcolor=&quot;#fdfddf&quot;&gt;&lt;a href=&quot;(?P&lt;download&gt;.*?)&quot;&gt;&#x27;</span>, re.S)</span><br><span class="line"><span class="keyword">for</span> href <span class="keyword">in</span> child_href_list:</span><br><span class="line">    child_resp = requests.get(href)</span><br><span class="line">    child_resp.encoding = <span class="string">&#x27;gb2312&#x27;</span></span><br><span class="line">    <span class="comment"># print(child_resp.text)</span></span><br><span class="line">    result3 = obj3.finditer(child_resp.text)</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> result3:</span><br><span class="line">        moviename = j.group(<span class="string">&quot;moviename&quot;</span>)</span><br><span class="line">        download = j.group(<span class="string">&quot;download&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(moviename)</span><br><span class="line">        <span class="built_in">print</span>(download)</span><br><span class="line">    <span class="comment"># break  # For testing</span></span><br><span class="line">    child_resp.close()</span><br></pre></td></tr></table></figure>

<p>Based on the known information, we write the regex expression, preprocess it, and get the movie name and torrent link.</p>
<p>Then we iterate through all links in the sub-page list to get all the 2022 must-watch movie names and torrents.</p>
<hr>
<h3 id="Complete-Code"><a href="#Complete-Code" class="headerlink" title="Complete Code"></a>Complete Code</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Approach:</span></span><br><span class="line"><span class="comment"># 1. Locate the 2022 Must-Watch Movies section</span></span><br><span class="line"><span class="comment"># 2. Extract sub-page links from the list</span></span><br><span class="line"><span class="comment"># 3. Request sub-page links to get download addresses (torrent links)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">domain = <span class="string">&quot;target_url_here&quot;</span>  <span class="comment"># domain is just another way of saying URL</span></span><br><span class="line">resp = requests.get(domain, verify=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># If error, might be https issue. Add &#x27;verify=False&#x27; to skip security verification</span></span><br><span class="line"><span class="comment"># print(resp.text)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Chinese encoding defaults to utf-8, but garbled text means encoding issue</span></span><br><span class="line"><span class="comment"># Observed &lt;META http-equiv=Content-Type content=&quot;text/html; charset=gb2312&quot;&gt;</span></span><br><span class="line"><span class="comment"># charset=gb2312, so use gb2312 encoding</span></span><br><span class="line">resp.encoding = <span class="string">&#x27;gb2312&#x27;</span>  <span class="comment"># Specify character set</span></span><br><span class="line"><span class="comment"># print(resp.text)</span></span><br><span class="line">resp.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Successfully located</span></span><br><span class="line">obj1 = re.<span class="built_in">compile</span>(<span class="string">r&quot;2022å¿…çœ‹çƒ­ç‰‡.*?&lt;ul&gt;(?P&lt;ul&gt;.*?)&lt;/ul&gt;&quot;</span>, re.S)</span><br><span class="line">result1 = obj1.finditer(resp.text)</span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> result1:</span><br><span class="line">    ul = it.group(<span class="string">&#x27;ul&#x27;</span>)</span><br><span class="line">    <span class="comment"># print(ul)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># In HTML, &lt;a&gt; tag is hyperlink, clicking jumps to href link</span></span><br><span class="line"><span class="comment"># title is tooltip text on hover, we mainly need sub-page link in href</span></span><br><span class="line"><span class="comment"># Extract sub-page links</span></span><br><span class="line">obj2 = re.<span class="built_in">compile</span>(<span class="string">r&quot;&lt;a href=&#x27;(?P&lt;href&gt;.*?)&#x27;&quot;</span>, re.S)</span><br><span class="line">result2 = obj2.finditer(ul)</span><br><span class="line">child_href_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> result2:</span><br><span class="line">    href = i.group(<span class="string">&#x27;href&#x27;</span>)</span><br><span class="line">    <span class="comment"># Concatenate sub-page URL: domain + sub-page address (strip extra slash)</span></span><br><span class="line">    child_href = domain + href.strip(<span class="string">&quot;/&quot;</span>)</span><br><span class="line">    <span class="comment"># print(child_href)</span></span><br><span class="line">    <span class="comment"># Store in list for convenience</span></span><br><span class="line">    child_href_list.append(child_href)  <span class="comment"># Save sub-page links</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Extract sub-page content</span></span><br><span class="line">obj3 = re.<span class="built_in">compile</span>(<span class="string">r&#x27;â—ç‰‡ å(?P&lt;moviename&gt;.*?)&lt;br /&gt;.*?&lt;td &#x27;</span></span><br><span class="line">                  <span class="string">r&#x27;style=&quot;WORD-WRAP: break-word&quot; bgcolor=&quot;#fdfddf&quot;&gt;&lt;a href=&quot;(?P&lt;download&gt;.*?)&quot;&gt;&#x27;</span>, re.S)</span><br><span class="line"><span class="keyword">for</span> href <span class="keyword">in</span> child_href_list:</span><br><span class="line">    child_resp = requests.get(href)</span><br><span class="line">    child_resp.encoding = <span class="string">&#x27;gb2312&#x27;</span></span><br><span class="line">    <span class="comment"># print(child_resp.text)</span></span><br><span class="line">    result3 = obj3.finditer(child_resp.text)</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> result3:</span><br><span class="line">        moviename = j.group(<span class="string">&quot;moviename&quot;</span>)</span><br><span class="line">        download = j.group(<span class="string">&quot;download&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(moviename)</span><br><span class="line">        <span class="built_in">print</span>(download)</span><br><span class="line">    <span class="comment"># break  # For testing</span></span><br><span class="line">    child_resp.close()</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/posts/07.-%E5%AE%9E%E6%88%98%EF%BC%9APython%E6%AD%A3%E5%88%99%E6%B3%95%E6%8A%93%E5%8F%96%E6%9F%90%E7%BD%91%E7%AB%992022%E5%BF%85%E7%9C%8B%E7%89%87%E8%BF%85%E9%9B%B7/646623511a10.png"></p>
<p>As you can see, both movie names and torrent links were successfully extracted. Done!</p>
<hr>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>Today we used regex to scrape 2022 must-watch movie names and their torrent download links, further practicing the use of the <code>re</code> module. Next chapter, weâ€™ll briefly introduce HTML syntax to prepare for learning bs4 and xpath later.</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/veckun">Likun Wang (ç‹ç«‹å¤)</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://your-domain.com/2022/12/29/en/07-Practical-Scraping-Movie-Torrent-Links-with-Python-Regex/">https://your-domain.com/2022/12/29/en/07-Practical-Scraping-Movie-Torrent-Links-with-Python-Regex/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/python/">python</a><a class="post-meta__tags" href="/tags/programming/">programming</a><a class="post-meta__tags" href="/tags/web-scraping/">web scraping</a><a class="post-meta__tags" href="/tags/pycharm/">pycharm</a><a class="post-meta__tags" href="/tags/regular-expressions/">regular expressions</a></div><div class="post-share"><div class="social-share" data-image="/images/posts/07.-%E5%AE%9E%E6%88%98%EF%BC%9APython%E6%AD%A3%E5%88%99%E6%B3%95%E6%8A%93%E5%8F%96%E6%9F%90%E7%BD%91%E7%AB%992022%E5%BF%85%E7%9C%8B%E7%89%87%E8%BF%85%E9%9B%B7/f09781cf5d77.png" data-sites="wechat,weibo,qq,twitter,facebook"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2022/12/29/en/08-Preparation-for-bs4-Parsing-Understanding-HTML-Basics/" title="08. Preparation for bs4 Parsing: Understanding HTML Basics"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">08. Preparation for bs4 Parsing: Understanding HTML Basics</div></div><div class="info-2"><div class="info-item-1"> This article was migrated from CSDN blogOriginal link: 08. Preparation for bs4 Parsing: Understanding HTML BasicsğŸ“Š 154 views | ğŸ‘ 2 likes | ğŸ’¬ 1 comment | â­ 3 favorites  Table of Contents Introduction Purpose HTML Basics  Systematic HTML Learning  Quick Overview    IntroductionThis series will cover three parsing methods: regex, bs4, and xpath. Weâ€™ve already learned regex parsing and built two practical projects, basically mastering this parsing method. When learning regex parsing, we also ...</div></div></div></a><a class="pagination-related" href="/2022/12/28/zh-CN/06.-%E5%AE%9E%E6%88%98%EF%BC%9APython%E6%AD%A3%E5%88%99%E6%B3%95%E6%8A%93%E5%8F%96%E6%9F%90%E7%94%B5%E5%BD%B1%E7%BD%91Top250%E4%BF%A1%E6%81%AF/" title="06. å®æˆ˜ï¼šPythonæ­£åˆ™æ³•æŠ“å–æŸç”µå½±ç½‘Top250ä¿¡æ¯"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/posts/06.-%E5%AE%9E%E6%88%98%EF%BC%9APython%E6%AD%A3%E5%88%99%E6%B3%95%E6%8A%93%E5%8F%96%E6%9F%90%E7%94%B5%E5%BD%B1%E7%BD%91Top250%E4%BF%A1%E6%81%AF/9546f4c712a0.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">06. å®æˆ˜ï¼šPythonæ­£åˆ™æ³•æŠ“å–æŸç”µå½±ç½‘Top250ä¿¡æ¯</div></div><div class="info-2"><div class="info-item-1"> æœ¬æ–‡è¿ç§»è‡ªCSDNåšå®¢åŸæ–‡é“¾æ¥ï¼š06. å®æˆ˜ï¼šPythonæ­£åˆ™æ³•æŠ“å–æŸç”µå½±ç½‘Top250ä¿¡æ¯ğŸ“Š 913 é˜…è¯» | ğŸ‘ 6 ç‚¹èµ | ğŸ’¬ 1 è¯„è®º | â­ 16 æ”¶è—  ç›®å½• å‰è¨€ éœ€æ±‚ æ€è·¯ ä»£ç å®ç° å®Œæ•´ä»£ç  è¿è¡Œç»“æœ æ€»ç»“   å‰è¨€ç»è¿‡å‰é¢å‡ èŠ‚çš„å­¦ä¹ ï¼Œæˆ‘ä»¬ç°åœ¨ç»ˆäºå…·æœ‰åšå°é¡¹ç›®çš„èƒ½åŠ›äº†ã€‚æˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯æˆ‘ä»¬ä¹‹å‰æ¶‰åŠè¿‡çš„æŸç”µå½±æ’è¡Œæ¦œï¼Œåˆ©ç”¨çˆ¬è™«å·¥å…·æŠ“å–Top250ï¼Œç”¨æ¥ç»ƒæ‰‹ã€‚  éœ€æ±‚æŠ“å–æŸç”µå½±Top250çš„â€œç”µå½±åç§°â€ï¼Œâ€œä¸Šæ˜ å¹´ä»½â€ï¼Œâ€œè¯„åˆ†â€ï¼Œâ€œè¯„åˆ†äººæ•°â€å››é¡¹å†…å®¹ï¼Œå¹¶å¦å­˜ä¸ºæ–‡ä»¶ã€‚   æ€è·¯æŸ¥çœ‹é¡µé¢æºä»£ç ï¼Œçœ‹æ•°æ®æ˜¯å¦åŒ…å«åœ¨æºä»£ç ä¸­ï¼Œå¦‚æœä¸åœ¨æºä»£ç ä¸­åˆ™è€ƒè™‘jsåŠ¨æ€åŠ è½½æ•°æ®ï¼Œéœ€è¦è§‚å¯Ÿæ‰¾åˆ°åŠ è½½æ•°æ®çš„æºå¤´ï¼Œä»è€ŒæŠ“å–æ•°æ®ï¼Œå¦åˆ™ç›´æ¥ç”¨æ­£åˆ™è§£ææºä»£ç å³å¯  å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬æ‰€éœ€è¦çš„æ•°æ®éƒ½åœ¨æºä»£ç ä¸­ï¼Œæ‰€ä»¥æˆ‘ä»¬ç›´æ¥ç”¨åˆšå­¦ä¹ åˆ°çš„reæ­£åˆ™è¡¨è¾¾å¼æ–¹æ³•è§£æå‡ºæˆ‘ä»¬æƒ³è¦çš„æ•°æ®å³å¯ï¼  ä»£ç å®ç°ç¬¬ä¸€æ­¥ï¼Œè€ç†Ÿäººäº†ï¼Œå…ˆæ‹¿åˆ°é¡µé¢æºç ï¼š python url = &#39;https://movie.douban.com/top250&#39; headers = { &quot;User-Agent&quot;: &...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2022/12/28/en/06-Practical-Scraping-Movie-Top250-with-Python-Regex/" title="06. Practical: Scraping Movie Top250 with Python Regex"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/posts/06.-%E5%AE%9E%E6%88%98%EF%BC%9APython%E6%AD%A3%E5%88%99%E6%B3%95%E6%8A%93%E5%8F%96%E6%9F%90%E7%94%B5%E5%BD%B1%E7%BD%91Top250%E4%BF%A1%E6%81%AF/9546f4c712a0.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-29</div><div class="info-item-2">06. Practical: Scraping Movie Top250 with Python Regex</div></div><div class="info-2"><div class="info-item-1"> This article was migrated from CSDN blogOriginal link: 06. Practical: Scraping Movie Top250 with Python RegexğŸ“Š 913 views | ğŸ‘ 6 likes | ğŸ’¬ 1 comment | â­ 16 favorites  Table of Contents Introduction Requirements Approach Code Implementation Complete Code Results Summary  IntroductionAfter learning the basics in previous chapters, we now have the ability to work on small projects. Our target is the movie ranking website we mentioned before - weâ€™ll scrape the Top 250 movies for practice.  Requ...</div></div></div></a><a class="pagination-related" href="/2023/01/01/en/12-XPath-Parsing-Introduction/" title="12. XPath Parsing Introduction"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/posts/12.-XPath%E8%A7%A3%E6%9E%90%E5%85%A5%E9%97%A8/7dcace80f3c2.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-02</div><div class="info-item-2">12. XPath Parsing Introduction</div></div><div class="info-2"><div class="info-item-1"> This article was migrated from CSDN blogOriginal link: 12. XPath Parsing IntroductionğŸ“Š 611 views | ğŸ‘ 2 likes | ğŸ’¬ 1 comment | â­ 6 favorites  Table of Contents Introduction Module Installation Basic XPath Concepts XPath Basic Syntax Complete Test Code XPath Advanced Usage Task 1: Process a resource file with xpath Task 2: Find tag location, like html tag Task 3: Find text content in each list item (li) of unordered list (ul) Task 4: Find text content in first list item (li) of unordered lis...</div></div></div></a><a class="pagination-related" href="/2023/01/04/en/18-Overview-How-to-Speed-Up-Web-Scraping/" title="18. Overview: How to Speed Up Web Scraping"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/posts/18.-%E6%A6%82%E8%BF%B0%E5%A6%82%E4%BD%95%E5%8A%A0%E5%BF%AB%E7%88%AC%E8%99%AB%E6%95%88%E7%8E%87/63a82f71b089.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-05</div><div class="info-item-2">18. Overview: How to Speed Up Web Scraping</div></div><div class="info-2"><div class="info-item-1"> This article was migrated from CSDN blogOriginal link: 18. Overview: How to Speed Up Web ScrapingğŸ“Š 281 views | ğŸ‘ 3 likes | ğŸ’¬ 1 comment | â­ 4 favorites  Table of Contents Introduction Overview Illustration  IntroductionOur previous scraping projects were small-scale and completed quickly. But weâ€™ll face a practical question: what if we need to scrape thousands of data items? Looping through thousands of pages executing code sequentially is clearly inefficient. How can we improve efficiency...</div></div></div></a><a class="pagination-related" href="/2022/12/30/en/10-Supplementary-Example-Scraping-Dynamic-JS-Vegetable-Price-Pages/" title="10. Supplementary Example: Scraping Dynamic JS Vegetable Price Pages"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/posts/10.-%E8%A1%A5%E5%85%85%E5%AE%9E%E4%BE%8B%EF%BC%9Ajs%E5%8A%A8%E6%80%81%E8%AF%B7%E6%B1%82%E8%8F%9C%E4%BB%B7%E7%BD%91%E9%A1%B5%E7%9A%84%E7%88%AC%E5%8F%96/6346d93934d9.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-31</div><div class="info-item-2">10. Supplementary Example: Scraping Dynamic JS Vegetable Price Pages</div></div><div class="info-2"><div class="info-item-1"> This article was migrated from CSDN blogOriginal link: 10. Supplementary Example: Scraping Dynamic JS Vegetable Price PagesğŸ“Š 301 views | ğŸ‘ 4 likes | ğŸ’¬ 2 comments | â­ 5 favorites  Table of Contents Introduction Approach Code Implementation Complete Code Summary  IntroductionA typical case for scraping vegetable prices is a Beijing wholesale market website, but its page has been redesigned and canâ€™t be scraped using bs4 parsing. Through analysis, we found it uses dynamic JS requests for the...</div></div></div></a><a class="pagination-related" href="/2022/12/30/en/09-bs4-Parsing-Basics-and-Examples/" title="09. bs4 Parsing Basics and Examples"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/posts/09.-bs4%E8%A7%A3%E6%9E%90%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%AE%9E%E4%BE%8B/3fc20ab2cc40.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-31</div><div class="info-item-2">09. bs4 Parsing Basics and Examples</div></div><div class="info-2"><div class="info-item-1"> This article was migrated from CSDN blogOriginal link: 09. bs4 Parsing Basics and ExamplesğŸ“Š 802 views | ğŸ‘ 4 likes | ğŸ’¬ 4 comments | â­ 6 favorites  Table of Contents Introduction Installing bs4 bs4 Usage Basics bs4 Example: Scraping Vegetable Prices Code Implementation Complete Code Important Reminder Summary  IntroductionWe now have basic HTML knowledge and can identify various elements in HTML source code. In this chapter, weâ€™ll formally learn bs4 usage and demonstrate its convenience wit...</div></div></div></a><a class="pagination-related" href="/2023/01/05/en/20-Thread-Pools-and-Process-Pools/" title="20. Thread Pools and Process Pools"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/posts/20.-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%B8%8E%E8%BF%9B%E7%A8%8B%E6%B1%A0/b7139937380e.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-06</div><div class="info-item-2">20. Thread Pools and Process Pools</div></div><div class="info-2"><div class="info-item-1"> This article was migrated from CSDN blogOriginal link: 20. Thread Pools and Process PoolsğŸ“Š 256 views | ğŸ‘ 3 likes | ğŸ’¬ 1 comment | â­ 4 favorites  Table of Contents Introduction Concepts Implementation Thread Pool Process Pool Results Summary  IntroductionWeâ€™ve learned about processes and threads, and understand the efficiency benefits of multiprocessing and multithreading. But how do we apply them practically? If we need to create a hundred threads, we canâ€™t write t0&#x3D;Thread through t99...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comments</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Likun Wang (ç‹ç«‹å¤)</div><div class="author-info-description">Algorithm Engineer | AI Engineer
Waseda University M.E.
Deep Learning & TPU Development
</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">302</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">311</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">21</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/veckun"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/veckun" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:vector_kun@ruri.waseda.jp" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a><a class="social-icon" href="https://linkedin.com/in/veckun" target="_blank" title="LinkedIn"><i class="fab fa-linkedin" style="color: #0077b5;"></i></a><a class="social-icon" href="javascript:void(0)" target="_blank" title="WeChat vectorkun"><i class="fab fa-weixin" style="color: #07c160;"></i></a><a class="social-icon" href="https://blog.csdn.net/m0_59180666" target="_blank" title="CSDN"><i class="fab fa-blogger" style="color: #fc5531;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Welcome to my blog! Sharing AI, algorithms & tech insights.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Objective"><span class="toc-number">2.</span> <span class="toc-text">Objective</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Approach"><span class="toc-number">3.</span> <span class="toc-text">Approach</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Code-Implementation"><span class="toc-number">4.</span> <span class="toc-text">Code Implementation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Step-1-Import-Libraries"><span class="toc-number">4.1.</span> <span class="toc-text">Step 1: Import Libraries</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Step-2-Request-Source-Code"><span class="toc-number">4.2.</span> <span class="toc-text">Step 2: Request Source Code</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Step-3-Debug-Step-2"><span class="toc-number">4.3.</span> <span class="toc-text">Step 3: Debug Step 2</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Step-4-Locate-Information-with-Regex"><span class="toc-number">4.4.</span> <span class="toc-text">Step 4: Locate Information with Regex</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Step-5-Access-and-Extract-Sub-page-Content"><span class="toc-number">4.5.</span> <span class="toc-text">Step 5: Access and Extract Sub-page Content</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Complete-Code"><span class="toc-number">5.</span> <span class="toc-text">Complete Code</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Results"><span class="toc-number">6.</span> <span class="toc-text">Results</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Summary"><span class="toc-number">7.</span> <span class="toc-text">Summary</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2026/01/04/en/Kiro-Batch-Registration-Vulnerability-Whistleblower/" title="On 'I Report Myself': The 'Modern-Day Hero' Behind Kiro's Batch Registration Vulnerability"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/posts/kiro-whistleblower.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="On 'I Report Myself': The 'Modern-Day Hero' Behind Kiro's Batch Registration Vulnerability"/></a><div class="content"><a class="title" href="/2026/01/04/en/Kiro-Batch-Registration-Vulnerability-Whistleblower/" title="On 'I Report Myself': The 'Modern-Day Hero' Behind Kiro's Batch Registration Vulnerability">On 'I Report Myself': The 'Modern-Day Hero' Behind Kiro's Batch Registration Vulnerability</a><time datetime="2026-01-04T15:00:00.000Z" title="Created 2026-01-05 00:00:00">2026-01-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/04/zh-CN/%E8%AE%BA%E3%80%8A%E6%88%91-%E4%B8%BE-%E6%8A%A5-%E6%88%91-%E8%87%AA-%E5%B7%B1%E3%80%8B%EF%BC%9AKiro-%E6%89%B9%E9%87%8F%E6%B3%A8%E5%86%8C%E6%BC%8F%E6%B4%9E%E8%83%8C%E5%90%8E%E7%9A%84%E2%80%9C%E5%BD%93%E4%BB%A3%E6%B4%BB%E9%9B%B7%E9%94%8B%E2%80%9D/" title="è®ºã€Šæˆ‘ ä¸¾ æŠ¥ æˆ‘ è‡ª å·±ã€‹ï¼šKiro æ‰¹é‡æ³¨å†Œæ¼æ´èƒŒåçš„&quot;å½“ä»£æ´»é›·é”‹&quot;"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/posts/kiro-whistleblower.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="è®ºã€Šæˆ‘ ä¸¾ æŠ¥ æˆ‘ è‡ª å·±ã€‹ï¼šKiro æ‰¹é‡æ³¨å†Œæ¼æ´èƒŒåçš„&quot;å½“ä»£æ´»é›·é”‹&quot;"/></a><div class="content"><a class="title" href="/2026/01/04/zh-CN/%E8%AE%BA%E3%80%8A%E6%88%91-%E4%B8%BE-%E6%8A%A5-%E6%88%91-%E8%87%AA-%E5%B7%B1%E3%80%8B%EF%BC%9AKiro-%E6%89%B9%E9%87%8F%E6%B3%A8%E5%86%8C%E6%BC%8F%E6%B4%9E%E8%83%8C%E5%90%8E%E7%9A%84%E2%80%9C%E5%BD%93%E4%BB%A3%E6%B4%BB%E9%9B%B7%E9%94%8B%E2%80%9D/" title="è®ºã€Šæˆ‘ ä¸¾ æŠ¥ æˆ‘ è‡ª å·±ã€‹ï¼šKiro æ‰¹é‡æ³¨å†Œæ¼æ´èƒŒåçš„&quot;å½“ä»£æ´»é›·é”‹&quot;">è®ºã€Šæˆ‘ ä¸¾ æŠ¥ æˆ‘ è‡ª å·±ã€‹ï¼šKiro æ‰¹é‡æ³¨å†Œæ¼æ´èƒŒåçš„&quot;å½“ä»£æ´»é›·é”‹&quot;</a><time datetime="2026-01-04T15:00:00.000Z" title="Created 2026-01-05 00:00:00">2026-01-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/10/12/en/Common-Archive-Formats-Explained/" title="Common Archive Formats Explained: Differences and Extraction Methods"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Common Archive Formats Explained: Differences and Extraction Methods"/></a><div class="content"><a class="title" href="/2025/10/12/en/Common-Archive-Formats-Explained/" title="Common Archive Formats Explained: Differences and Extraction Methods">Common Archive Formats Explained: Differences and Extraction Methods</a><time datetime="2025-10-12T15:00:00.000Z" title="Created 2025-10-13 00:00:00">2025-10-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/10/12/zh-CN/%E5%B8%B8%E8%A7%81%E5%8E%8B%E7%BC%A9%E5%8C%85%E6%A0%BC%E5%BC%8F%E8%AF%A6%E8%A7%A3%EF%BC%9A%E5%8C%BA%E5%88%AB%E5%8F%8A%E5%9C%A8%E4%B8%8D%E5%90%8C%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E8%A7%A3%E5%8E%8B%E6%96%B9%E5%BC%8F/" title="å¸¸è§å‹ç¼©åŒ…æ ¼å¼è¯¦è§£ï¼šåŒºåˆ«åŠåœ¨ä¸åŒç³»ç»Ÿä¸­çš„è§£å‹æ–¹å¼"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="å¸¸è§å‹ç¼©åŒ…æ ¼å¼è¯¦è§£ï¼šåŒºåˆ«åŠåœ¨ä¸åŒç³»ç»Ÿä¸­çš„è§£å‹æ–¹å¼"/></a><div class="content"><a class="title" href="/2025/10/12/zh-CN/%E5%B8%B8%E8%A7%81%E5%8E%8B%E7%BC%A9%E5%8C%85%E6%A0%BC%E5%BC%8F%E8%AF%A6%E8%A7%A3%EF%BC%9A%E5%8C%BA%E5%88%AB%E5%8F%8A%E5%9C%A8%E4%B8%8D%E5%90%8C%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E8%A7%A3%E5%8E%8B%E6%96%B9%E5%BC%8F/" title="å¸¸è§å‹ç¼©åŒ…æ ¼å¼è¯¦è§£ï¼šåŒºåˆ«åŠåœ¨ä¸åŒç³»ç»Ÿä¸­çš„è§£å‹æ–¹å¼">å¸¸è§å‹ç¼©åŒ…æ ¼å¼è¯¦è§£ï¼šåŒºåˆ«åŠåœ¨ä¸åŒç³»ç»Ÿä¸­çš„è§£å‹æ–¹å¼</a><time datetime="2025-10-12T15:00:00.000Z" title="Created 2025-10-13 00:00:00">2025-10-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/18/en/Master-Python-Debugger-pdb-in-10-Minutes/" title="Master Python Debugger pdb in 10 Minutes"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/posts/10%E5%88%86%E9%92%9F%E6%8E%8C%E6%8F%A1Python%E8%B0%83%E8%AF%95%E5%99%A8pdb/0d565b653736.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Master Python Debugger pdb in 10 Minutes"/></a><div class="content"><a class="title" href="/2025/09/18/en/Master-Python-Debugger-pdb-in-10-Minutes/" title="Master Python Debugger pdb in 10 Minutes">Master Python Debugger pdb in 10 Minutes</a><time datetime="2025-09-18T15:00:00.000Z" title="Created 2025-09-19 00:00:00">2025-09-19</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By Likun Wang (ç‹ç«‹å¤)</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.1.1</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.3</a></span></div><div class="footer_custom_text"><p>Likun Wang | Algorithm Engineer</p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll to Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.3"></script><script src="/js/main.js?v=5.5.3"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@6.1.7/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.2.0/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@19.1.3/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        loader: {
          load: [
            // Four font extension packages (optional)
            //- '[tex]/bbm',
            //- '[tex]/bboldx',
            //- '[tex]/dsfont',
            '[tex]/mhchem'
          ],
          paths: {
            'mathjax-newcm': '[mathjax]/../@mathjax/mathjax-newcm-font',

            //- // Four font extension packages (optional)
            //- 'mathjax-bbm-extension': '[mathjax]/../@mathjax/mathjax-bbm-font-extension',
            //- 'mathjax-bboldx-extension': '[mathjax]/../@mathjax/mathjax-bboldx-font-extension',
            //- 'mathjax-dsfont-extension': '[mathjax]/../@mathjax/mathjax-dsfont-font-extension',
            'mathjax-mhchem-extension': '[mathjax]/../@mathjax/mathjax-mhchem-font-extension'
          }
        },
        output: {
          font: 'mathjax-newcm',
        },
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'ams',
          packages: {
            '[+]': [
              'mhchem'
            ]
          }
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          menuOptions: {
            settings: {
              enrich: false  // Turn off Braille and voice narration text automatic generation
            }
          },
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax@4.0.0/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const config = mermaidSrc.dataset.config ? JSON.parse(mermaidSrc.dataset.config) : {}
      if (!config.theme) {
        config.theme = theme
      }
      const mermaidThemeConfig = `%%{init: ${JSON.stringify(config)}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://your-twikoo.vercel.app',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const init = (el = document, path = location.pathname) => {
    twikoo.init({
      el: el.querySelector('#twikoo-wrap'),
      envId: 'https://your-twikoo.vercel.app',
      region: '',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      },
      ...option,
      path: isShuoshuo ? path : (option && option.path) || path
    })

    GLOBAL_CONFIG_SITE.pageType === 'post' && getCount()

    isShuoshuo && (window.shuoshuoComment.destroyTwikoo = () => {
      if (el.children.length) {
        el.innerHTML = ''
        el.classList.add('no-comment')
      }
    })
  }

  const loadTwikoo = (el, path) => {
    if (typeof twikoo === 'object') setTimeout(() => init(el, path), 0)
    else btf.getScript('https://cdn.jsdelivr.net/npm/twikoo@1.6.44/dist/twikoo.all.min.js').then(() => init(el, path))
  }

  if (isShuoshuo) {
    'Twikoo' === 'Twikoo'
      ? window.shuoshuoComment = { loadComment: loadTwikoo }
      : window.loadOtherComment = loadTwikoo
    return
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><script src="/js/lang-router.js"></script><script src="/js/csdn-stats.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js" defer="defer"></script><script>document.addEventListener('DOMContentLoaded', () => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => {
      try {
        fn()
      } catch (err) {
        console.debug('Pjax callback failed:', err)
      }
    })
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      true
        ? pjax.loadUrl('/404.html')
        : window.location.href = e.request.responseURL
    }
  })
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><i class="fas fa-spinner fa-pulse" id="loading-status" hidden="hidden"></i><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading Database</span></div><div class="local-search-input"><input placeholder="Search..." type="text"/></div><hr/><div id="local-search-results"></div><div class="ais-Pagination" id="local-search-pagination" style="display:none;"><ul class="ais-Pagination-list"></ul></div><div id="local-search-stats"></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=5.5.3"></script></div></div></body></html>