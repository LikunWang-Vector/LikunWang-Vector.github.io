---
title: "33. å®æˆ˜ï¼šå®ç°æŸç½‘ç«™åº—é“ºä¿¡æ¯çš„æŸ¥è¯¢ä¸æ‰¹é‡æŠ“å–ï¼ˆé™„æºç ï¼‰"
date: 2023-01-28
updated: 2023-01-28
categories:
  - Pythonçˆ¬è™«å…¥é—¨ã€è¿›é˜¶ä¸å®æˆ˜
tags:
  - python
  - å¼€å‘è¯­è¨€
  - request
  - æ•°æ®åˆ†æ
  - json
csdn_views: 1321
csdn_likes: 3
csdn_comments: 3
csdn_favorites: 6
csdn_url: https://blog.csdn.net/m0_59180666/article/details/128775055
cover: /images/posts/33.-å®æˆ˜ï¼šå®ç°æŸç½‘ç«™åº—é“ºä¿¡æ¯çš„æŸ¥è¯¢ä¸æ‰¹é‡æŠ“å–ï¼ˆé™„æºç ï¼‰/a3f69c03ab5b.png
lang_pair:
  en: "33. Practical: Scraping Store Information Query System"
---

> æœ¬æ–‡è¿ç§»è‡ªCSDNåšå®¢
> åŸæ–‡é“¾æ¥ï¼š[33. å®æˆ˜ï¼šå®ç°æŸç½‘ç«™åº—é“ºä¿¡æ¯çš„æŸ¥è¯¢ä¸æ‰¹é‡æŠ“å–ï¼ˆé™„æºç ï¼‰](https://blog.csdn.net/m0_59180666/article/details/128775055)
> ğŸ“Š 1321 é˜…è¯» | ğŸ‘ 3 ç‚¹èµ | ğŸ’¬ 3 è¯„è®º | â­ 6 æ”¶è—

**ç›®å½•**

å‰è¨€

ç›®çš„

æ€è·¯

ä»£ç å®ç°

1\. è¯·æ±‚URLï¼Œè·å–æºä»£ç 

2\. è§£ææºä»£ç ï¼Œè·å–æ•°æ®

3\. å®Œå–„ä¿å­˜æ•°æ®çš„å‡½æ•°save_data

4\. ç†æ¸…mainå‡½æ•°é€»è¾‘ï¼Œå¾ªç¯ä¼ é€’æ¯ä¸€é¡µæœ‰æ•ˆä¿¡æ¯çš„å‚æ•°

å®Œæ•´ä»£ç 

è¿è¡Œæ•ˆæœ

æ€»ç»“

* * *

### å‰è¨€

è¿‘æ—¥ï¼Œæˆ‘ä»¬æ¯å‘¨å››éƒ½èƒ½åˆ·åˆ°ä¸€å †â€œç–¯ç‹‚æ˜ŸæœŸå››â€çš„æ¢—å›¾æˆ–è€…æ¶ˆæ¯ï¼Œé‚£ä¹ˆå¦‚æœçœŸçš„Vivo50ï¼Œæˆ‘ä»¬è¯¥å»å“ªé‡Œæ¶ˆè´¹å‘¢ï¼Ÿå‡è®¾æˆ‘ä»¬æ¥åˆ°ä¸€ä¸ªæ–°çš„åŸå¸‚ï¼Œæˆ–è€…æƒ³çŸ¥é“æˆ‘ä»¬çˆ†äº†50é‡‘å¸ç½‘å‹æ‰€åœ¨çš„åŸå¸‚åˆ°åº•æœ‰æ²¡æœ‰ç›¸å…³åº—é“ºè¯¥æ€ä¹ˆåŠï¼Ÿ

é‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥æ¥è¿›è¡Œä¸€ä¸ªå°å°çš„çˆ¬è™«ï¼Œä¸€æ¬¡ç¼–ç¨‹ï¼Œæ–¹ä¾¿åé¢çš„æ¯ä¸€æ¬¡æŸ¥è¯¢ã€‚

* * *

### ç›®çš„

1\. å®ç°è¾“å…¥ä»»æ„å…³é”®è¯æŸ¥è¯¢åº—é“º

2\. å°†æ‰€æœ‰åº—é“ºä¿¡æ¯è¾“å‡ºåˆ°æ§åˆ¶å°ï¼Œè‡ªè¡Œé€‰æ‹©æ˜¯å¦ä¿å­˜åˆ°æœ¬åœ°

3\. è¦æ±‚æ˜¯å°è£…å¥½çš„ç»“æœï¼Œå°†å„ä¸ªåŠŸèƒ½åˆ†ç¦»

* * *

### æ€è·¯

1\. è¯·æ±‚URLï¼Œè·å–æºä»£ç 

2\. è§£ææºä»£ç ï¼Œè·å–æ•°æ®

3\. å®Œå–„é€»è¾‘

* * *

### ä»£ç å®ç°

#### 1\. è¯·æ±‚URLï¼Œè·å–æºä»£ç 

é¦–å…ˆè®¿é—®è¯·æ±‚åº—é“ºä¿¡æ¯é¡µé¢ï¼ˆURLä¸ä¾¿å±•ç¤ºï¼Œ**æ”¾åœ¨è¯„è®ºåŒºäº†** ï¼‰ï¼Œå‘ç°æˆ‘ä»¬æŸ¥è¯¢ä»¥åé¡µé¢URLæ˜¯ä¸å˜çš„ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å¾ˆè‡ªç„¶çš„æƒ³åˆ°æ˜¯ä¸€ä¸ªåŠ¨æ€è¯·æ±‚ã€‚

![](/images/posts/33.-å®æˆ˜ï¼šå®ç°æŸç½‘ç«™åº—é“ºä¿¡æ¯çš„æŸ¥è¯¢ä¸æ‰¹é‡æŠ“å–ï¼ˆé™„æºç ï¼‰/a3f69c03ab5b.png)

é‚£ä¹ˆå¾ˆç†Ÿæ‚‰ï¼Œæ‰“å¼€æŠ“åŒ…å·¥å…·ï¼Œè¾“å…¥ä»»æ„å…³é”®è¯ï¼ŒæŸ¥è¯¢åº—é“ºï¼Œå‘ç°æ‹¿åˆ°äº†ä¸€ä¸ªjsonï¼š

![](/images/posts/33.-å®æˆ˜ï¼šå®ç°æŸç½‘ç«™åº—é“ºä¿¡æ¯çš„æŸ¥è¯¢ä¸æ‰¹é‡æŠ“å–ï¼ˆé™„æºç ï¼‰/53f21a066197.png)

æ‰“å¼€æ ‡å¤´é¡¹ï¼Œå¯ä»¥æ‹¿åˆ°URLä¸è¯·æ±‚æ–¹å¼ï¼Œæ‰“å¼€è´Ÿè½½ï¼Œå¯ä»¥æ‹¿åˆ°è¯·æ±‚æ‰€éœ€çš„å‚æ•°ï¼Œæ‰“å¼€é¢„è§ˆï¼Œå¯ä»¥å‘ç°é‡Œé¢åŒ…å«äº†æˆ‘ä»¬æƒ³è¦çš„æ•°æ®ã€‚

```python import requests import json import csv # å…¨å±€å˜é‡URLä¸UA url = 'è§è¯„è®ºåŒº' UA = { "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36 Edg/109.0.1518.61" } # è¯·æ±‚URLï¼Œè·å–æºä»£ç  def request_url(link, headers, params): resp = requests.post(url=link, headers=headers, params=params) resp.encoding = 'utf-8' return resp.text ``` 

#### 2\. è§£ææºä»£ç ï¼Œè·å–æ•°æ®

è§£ææºä»£ç éœ€è¦ä¸¤ä¸ªå˜é‡ï¼šè¯·æ±‚ç»“æœä¸å­˜å‚¨è¯·æ±‚ã€‚å‚æ•°ä¸€å¾ˆå¥½ç†è§£ï¼Œå®ƒå°±æ˜¯æˆ‘ä»¬è¦è§£æçš„æ•°æ®ï¼Œå‚æ•°äºŒæ˜¯æˆ‘ä»¬è‡ªå®šä¹‰çš„æ˜¯å¦å­˜å‚¨åˆ°æœ¬åœ°æ–‡ä»¶çš„ä¸€ä¸ªå˜é‡ï¼Œå½“**å®ƒä¸ºyæ—¶é€‰æ‹©è°ƒç”¨save_dataå‡½æ•°å°†ä¿¡æ¯ä¿å­˜åˆ°æœ¬åœ°csvæ–‡ä»¶ï¼Œä¸ºnæ—¶ä¸è°ƒç”¨ï¼Œä»…åœ¨æ§åˆ¶å°è¾“å‡º** ã€‚

```python # è§£æè¯·æ±‚åˆ°çš„ä¿¡æ¯ def parse_data(resp, save): data = json.loads(resp) if len(data["Table1"]) == 0: return True # å¦‚æœTable1åŒ…å«ä¿¡æ¯ï¼Œé‚£å°±éå†æ‹¿å‡ºæ¯ä¸€æ¡ for store_dict in data["Table1"]: print(store_dict) if save == 'y': save_data(store_dict) ``` 

#### 3\. å®Œå–„ä¿å­˜æ•°æ®çš„å‡½æ•°save_data

```python # ä¿å­˜åº—é“ºä¿¡æ¯åˆ°æœ¬åœ° def save_data(store_dict): with open('2_KFC_Store_List.csv', mode='a+', newline='', encoding='utf-8') as f: csvwriter = csv.writer(f) storeName = store_dict['storeName'] addressDetail = store_dict['addressDetail'] pro = store_dict['pro'] provinceName = store_dict['provinceName'] cityName = store_dict['cityName'] csvwriter.writerow([storeName, addressDetail, pro, provinceName, cityName]) ``` 

#### 4\. ç†æ¸…mainå‡½æ•°é€»è¾‘ï¼Œå¾ªç¯ä¼ é€’æ¯ä¸€é¡µæœ‰æ•ˆä¿¡æ¯çš„å‚æ•°

```python def main(): pageIndex = 1 store_name = input("æ¬¢è¿ä½¿ç”¨KFCåº—é“ºæŸ¥è¯¢ç³»ç»Ÿï¼è¯·è¾“å…¥æ‚¨æƒ³è¦æŸ¥è¯¢åº—é“ºçš„å…³é”®è¯\n") save_query = input("æ˜¯å¦ä¿å­˜åº—é“ºä¿¡æ¯åˆ°æœ¬åœ°ï¼Ÿï¼ˆy/nï¼‰\n") if save_query == 'n': print("æ­£åœ¨å¤„ç†ä¿¡æ¯...åº—é“ºä¿¡æ¯å°†æ‰“å°åˆ°æ§åˆ¶å°...") if save_query == 'y': print("æ­£åœ¨å¤„ç†ä¿¡æ¯...åº—é“ºä¿¡æ¯å°†æ‰“å°åˆ°æ§åˆ¶å°å¹¶ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶'2_KFC_Store_List.csv'...") while True: data_dict = { "cname": "", "pid": "", "keyword": store_name, "pageIndex": pageIndex, "pageSize": 10 } resp = request_url(url, UA, data_dict) if parse_data(resp, save_query): break else: pageIndex += 1 if __name__ == '__main__': main() ``` 

å¦‚ä¸Šè¿°ä»£ç ï¼Œ **å½“è§£ææ•°æ®å‡½æ•°æ‹¿åˆ°çš„åº—é“ºä¿¡æ¯ä¸ºç©ºæ—¶ä¼šè¿”å›Trueï¼Œå½“Trueæ—¶å°±ç»“æŸå¾ªç¯ï¼Œå¦åˆ™é¡µç +1ç»§ç»­ç¿»é¡µ** ã€‚

åŒæ—¶ä¹Ÿèƒ½æ³¨æ„åˆ°ä¸»å‡½æ•°è¿è¡Œå‰è¦å…ˆè¾“å…¥ä¸¤ä¸ªå‚æ•°ï¼Œä¸€ä¸ªæ˜¯paramsä¸­å¿…éœ€çš„æŸ¥è¯¢å…³é”®è¯keywordï¼Œå¦ä¸€ä¸ªæ˜¯æ˜¯å¦ä¿å­˜ä¿¡æ¯åˆ°æœ¬åœ°çš„ä¸€ä¸ªå‚æ•°ï¼Œä¸ºyæˆ–nã€‚

* * *

### å®Œæ•´ä»£ç 

```python import requests import json import csv # å…¨å±€å˜é‡URLä¸UA url = 'è§è¯„è®ºåŒº' UA = { "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36 Edg/109.0.1518.61" } # è¯·æ±‚URLï¼Œè·å–æºä»£ç  def request_url(link, headers, params): resp = requests.post(url=link, headers=headers, params=params) resp.encoding = 'utf-8' return resp.text # è§£æè¯·æ±‚åˆ°çš„ä¿¡æ¯ def parse_data(resp, save): data = json.loads(resp) if len(data["Table1"]) == 0: return True # å¦‚æœTable1åŒ…å«ä¿¡æ¯ï¼Œé‚£å°±éå†æ‹¿å‡ºæ¯ä¸€æ¡ for store_dict in data["Table1"]: print(store_dict) if save == 'y': save_data(store_dict) # ä¿å­˜åº—é“ºä¿¡æ¯åˆ°æœ¬åœ° def save_data(store_dict): with open('2_KFC_Store_List.csv', mode='a+', newline='', encoding='utf-8') as f: csvwriter = csv.writer(f) storeName = store_dict['storeName'] addressDetail = store_dict['addressDetail'] pro = store_dict['pro'] provinceName = store_dict['provinceName'] cityName = store_dict['cityName'] csvwriter.writerow([storeName, addressDetail, pro, provinceName, cityName]) def main(): pageIndex = 1 store_name = input("æ¬¢è¿ä½¿ç”¨KFCåº—é“ºæŸ¥è¯¢ç³»ç»Ÿï¼è¯·è¾“å…¥æ‚¨æƒ³è¦æŸ¥è¯¢åº—é“ºçš„å…³é”®è¯\n") save_query = input("æ˜¯å¦ä¿å­˜åº—é“ºä¿¡æ¯åˆ°æœ¬åœ°ï¼Ÿï¼ˆy/nï¼‰\n") if save_query == 'n': print("æ­£åœ¨å¤„ç†ä¿¡æ¯...åº—é“ºä¿¡æ¯å°†æ‰“å°åˆ°æ§åˆ¶å°...") if save_query == 'y': print("æ­£åœ¨å¤„ç†ä¿¡æ¯...åº—é“ºä¿¡æ¯å°†æ‰“å°åˆ°æ§åˆ¶å°å¹¶ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶'2_KFC_Store_List.csv'...") while True: data_dict = { "cname": "", "pid": "", "keyword": store_name, "pageIndex": pageIndex, "pageSize": 10 } resp = request_url(url, UA, data_dict) if parse_data(resp, save_query): break else: pageIndex += 1 if __name__ == '__main__': main() ``` 

* * *

### è¿è¡Œæ•ˆæœ

![](/images/posts/33.-å®æˆ˜ï¼šå®ç°æŸç½‘ç«™åº—é“ºä¿¡æ¯çš„æŸ¥è¯¢ä¸æ‰¹é‡æŠ“å–ï¼ˆé™„æºç ï¼‰/1f8791f8bf6d.png)

![](/images/posts/33.-å®æˆ˜ï¼šå®ç°æŸç½‘ç«™åº—é“ºä¿¡æ¯çš„æŸ¥è¯¢ä¸æ‰¹é‡æŠ“å–ï¼ˆé™„æºç ï¼‰/7ee1c1c340dd.png)

* * *

### æ€»ç»“

æœ¬èŠ‚æˆ‘ä»¬ç»ƒä¹ äº†æŠ“å–æŒ‡å®šå…³é”®è¯çš„æŸå¿«é¤æ‰€æœ‰åº—é“ºä¿¡æ¯ï¼Œè¾ƒä¸ºç»¼åˆï¼Œä¸»è¦å­¦ä¹ æ€è·¯ï¼Œå¯ä»¥ä¸¾ä¸€åä¸‰ã€‚
