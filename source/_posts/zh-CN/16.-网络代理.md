---
title: "16. 网络代理"
date: 2023-01-04
updated: 2023-01-04
categories:
  - Python爬虫入门、进阶与实战
tags:
  - 网络
  - 代理模式
  - 爬虫
  - 数据分析
  - python
csdn_views: 435
csdn_likes: 1
csdn_comments: 1
csdn_favorites: 3
csdn_url: https://blog.csdn.net/m0_59180666/article/details/128555651
cover: /images/posts/16.-网络代理/2c0552b58e18.png
lang_pair:
  en: "16. Network Proxies"
---

> 本文迁移自CSDN博客
> 原文链接：[16. 网络代理](https://blog.csdn.net/m0_59180666/article/details/128555651)
> 📊 435 阅读 | 👍 1 点赞 | 💬 1 评论 | ⭐ 3 收藏

**目录**

前言

代理的原理

如何在Python中使用代理

总结

* * *

### 前言

你是否遇到过这样的情况：当我们在短时间反复抓取一个网站时，由于请求过于频繁，或者请求网络的时候没有关闭请求端口(resp.close())，服务器就会对我们的IP进行封锁达到反爬的目的。这个时候我们该怎么办？答案就是通过网络代理的方式来解决。

在这里特别说明：网络代理深入了解的话会涉及到一些灰色产业，我们不到万不得已千万不要贸然去使用。我们平日小体量的爬虫是不足以让服务器封锁IP的，除非我们的IP已经因为各种莫名其妙原因被封锁，或者我们的爬虫体量太大，需要一秒钟内要访问上万次等，这些情况我们可以适度使用网络代理来保证工程进行。

* * *

### 代理的原理

![](/images/posts/16.-网络代理/2c0552b58e18.png)

由图可知，目标服务器接收到的是代理服务器的请求，请求中包含的IP也是代理服务器的IP，它不知道在代理背后的你的IP。这样就能避免本机IP暴露在目标服务器中，从而避免被封锁的风险。

再拓展一点想，假如我们想要一秒内发送一千条数据，那我们可以把一千次请求分给一千个IP（代理池）来发送，这样在目标服务器看来就是一千个用户的请求操作，一般不会有大动作......

下面就不深入讨论了，感兴趣的同学可以再自行了解拓展......

* * *

### 如何在Python中使用代理

```python # 原理. 通过第三方的一个机器去发送请求 import requests # 47.92.113.71:80 proxies = { "https": "https://47.92.113.71:80" } resp = requests.get("https://www.baidu.com", proxies=proxies) resp.encoding = 'utf-8' print(resp.text) ``` 

以百度为例，我们在在网上随便找一个免费代理网随便拿一条可使用的IP来测试。我们可以发现运行以后还可以拿到我们熟悉的百度源代码，只不过速度慢了一点。

* * *

### 总结

今天我们认识了网络代理及其工作原理，但是我们也要谨记不要乱用代理，属于灰色产业范畴，而且代理IP也是时好时坏的，不稳定，我们不作更深入讨论，大家如果感兴趣可以自行查阅资料。
