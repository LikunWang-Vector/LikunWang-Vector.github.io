---
title: "09. bs4解析基础与实例"
date: 2022-12-31
updated: 2022-12-31
categories:
  - Python爬虫入门、进阶与实战
tags:
  - python
  - 开发语言
  - 爬虫
  - html
csdn_views: 802
csdn_likes: 4
csdn_comments: 4
csdn_favorites: 6
csdn_url: https://blog.csdn.net/m0_59180666/article/details/128505916
cover: /images/posts/09.-bs4解析基础与实例/3fc20ab2cc40.png
lang_pair:
  en: "09. bs4 Parsing Basics and Examples"
---

> 本文迁移自CSDN博客
> 原文链接：[09. bs4解析基础与实例](https://blog.csdn.net/m0_59180666/article/details/128505916)
> 📊 802 阅读 | 👍 4 点赞 | 💬 4 评论 | ⭐ 6 收藏

**目录**

前言

bs4的安装

bs4使用基础

bs4实例——获取某网站菜价

代码实现

完整代码

重要提醒

总结

* * *

### 前言

我们已经具备了基本的HTML知识，能够简单的识别HTML源代码中的各类元素。这一节我们将正式学习bs4的用法，并用一个实例来展示它的方便之处。可以说，相比于正则法，bs4是非常简单的。

* * *

### bs4的安装

没有安装过Python模块的同学可以参照我在requests章节的安装模块部分，把requests替换成bs4就可以了。

传送门：[Python模块安装的三种方式](https://blog.csdn.net/m0_59180666/article/details/128471531?spm=1001.2014.3001.5501 "Python模块安装的三种方式")

当然，大多数看到这一节的同学应该已经懂得模块的安装了，bs4模块安装如下：

```python pip install bs4 -i https://pypi.tuna.tsinghua.edu.cn/simple ``` 

* * *

### bs4使用基础

BeautifulSoup对象获取html中的内容主要通过两个方法来完成：

  * find()
  * find_all() 

![](/images/posts/09.-bs4解析基础与实例/3fc20ab2cc40.png)

不论是 find 还是 find_all，参数几乎是一致的 
  * **语法：** find(标签, 属性=值) 意思是在页面中查找xxx标签，并且标签的xxx属性必须是xxx值

例如，find('div' , age=18) 含义就是在页面中查找div标签，并且属性age必须是18的这个标签

find_all() 用法和 find() 几乎一致。find() 查找一个，find_all() 查找页面中所有的。

* * *

### bs4实例——获取某网站菜价

由已知可得，只要源代码中有数据，我们就能通过bs4轻松找到并提取出来。

目的：抓取某网站的菜价表并把所有信息输入到csv文件中。

#### 代码实现

第一步，老规矩，先获取源代码

```python # 拿到页面源代码 url = "在评论区" resp = requests.get(url) # print(resp.text) ``` 

第二步，把页面源代码直接全部丢给BeautifulSoup进行预处理，就可以通过bs对象得到该页面的所有html标签了。

```python # 1. 生成bs对象 page = BeautifulSoup(resp.text, "html.parser") # 指定html解析器 ``` 

第三步，找到我们想要的菜价表位置

![](/images/posts/09.-bs4解析基础与实例/59077596e46e.png)

使用的是find函数。我们用的最多的就是前两个，第一个就是只找一个，第二个是查找所有的。

我们在源代码中可以看到，我们想要的菜价数据全部被包裹在<table>标签中，这意味着被包含在表格里。而表格是由<tr>和<td>组成的，也就是行与列。

这下思路就明确了：先定位到表格，再获得所有行，再把所有行中的数据依次存入csv文件。

首先查看源代码，定位表格：

![](/images/posts/09.-bs4解析基础与实例/484dbf500f90.png)

可以看到表格标签中有一个属性值，并且是首次出现，那么我们就可以通过find精准的把他找出来 

```python # 2. 从bs对象中查找数据 # find(标签, 属性=值)：找第一个 # find_all(标签, 属性=值)：找全部 # table = page.find("table",class_="price-table") # class是python中的关键字，加_以示区别 # 另一种写法： table = page.find("table", attrs={"class": "price-table"}) # 和上一行是一个意思，此时可以避免class # print(table) ``` 

下一步，定位所有行

```python # 不想要列名那一行（表头），只想要底下的数据，即拿到所有数据行 trs = table.find_all("tr")[1:] # tr是行的意思 ``` 

因为表格还存在表头，我们不想要的话就可以从第一行开始切片，这样就不会拿到表头了。

最后，遍历所有行，把其中的数据拿出来

```python for tr in trs: # 每一行 tds = tr.find_all("td") # td表示单元格。拿到每行中的所有td # print(tds[0]) # 名字、产地、均价（元/公斤）、规格、日期 name = tds[0].text # .text表示拿到被标签标记的内容 place = tds[1].text avg_price = tds[2].text spec = tds[3].text date = tds[4].text # print(name,place,avg_price,spec,date) csvwriter.writerow([name, place, avg_price, spec, date]) f.close() print("over!!!") resp.close() ``` 

这样我们就顺利的把数据写入文件了。一定要记得要关闭文件并且关闭网络请求，这是一个好习惯，希望大家保持。

* * *

### 完整代码

```python # 安装 # pip install bs4 -i 清华 # 1. 拿到页面源代码 # 2. 使用bs4进行解析. 拿到数据 import requests from bs4 import BeautifulSoup import csv # 拿到页面源代码 url = "在评论区" resp = requests.get(url) # print(resp.text) f = open("广州江南菜价.csv", mode="w", newline="", encoding="utf-8") csvwriter = csv.writer(f) # 使用bs4解析数据（两步） # 1. 生成bs对象 page = BeautifulSoup(resp.text, "html.parser") # 指定html解析器 # 2. 从bs对象中查找数据 # find(标签, 属性=值)：找第一个 # find_all(标签, 属性=值)：找全部 # table = page.find("table",class_="price-table") # class是python中的关键字，加_以示区别 # 另一种写法： table = page.find("table", attrs={"class": "price-table"}) # 和上一行是一个意思，此时可以避免class # print(table) # 不想要列名那一行（表头），只想要底下的数据，即拿到所有数据行 trs = table.find_all("tr")[1:] # tr是行的意思 for tr in trs: # 每一行 tds = tr.find_all("td") # td表示单元格。拿到每行中的所有td # print(tds[0]) # 名字、产地、均价（元/公斤）、规格、日期 name = tds[0].text # .text表示拿到被标签标记的内容 place = tds[1].text avg_price = tds[2].text spec = tds[3].text date = tds[4].text # print(name,place,avg_price,spec,date) csvwriter.writerow([name, place, avg_price, spec, date]) f.close() print("over!!!") resp.close() ``` 

* * *

### 重要提醒

大家可以看到本例涉及的网站一共有一万多页，我们作为初学者一定不要盲目的去把所有数据都扒拿到！一个是没有什么用处，再一个是对网站服务器的负担很大，相当于搞破坏了，所以大家还是悠着点，适量的去试几页练手就好！当然也可以修改源代码里面的url部分或者套一个for循环来自动进行换页爬取。

* * *

### 总结

今天我们认识了bs4解析方式，也以一个实例进行训练，获取了某网站的菜价，明显感觉到bs4比起正则的简单与便捷。当然，我们也应铭记不要对网站进行高频词的访问，不然就类似于DDoS攻击了，对于网站服务器很不友好。
